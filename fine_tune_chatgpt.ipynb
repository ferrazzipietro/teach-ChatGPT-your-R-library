{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "api_key: YOUR-API-KEY\n",
      "model_engine: MODEL-TO-FINETUNE\n",
      "source_functions_loc1: PATH-TO-R-FUNCTIONS\n",
      "ENV_NAME: CONDA-VIRTUAL-ENV\n",
      "suffix: SUFFIX-TO-ADD-TO-THE-MODEL-NAME\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Read the JSON file\n",
    "with open('config.json') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Convert the JSON fields to variables\n",
    "api_key = config['api_key']\n",
    "model_engine = config['model_engine']\n",
    "source_functions_loc1 = config['source_functions_loc1']\n",
    "ENV_NAME = config['ENV_NAME']\n",
    "suffix = config['suffix']\n",
    "\n",
    "# Print the variables\n",
    "print(\"api_key:\", api_key)\n",
    "print(\"model_engine:\", model_engine)\n",
    "print(\"source_functions_loc1:\", source_functions_loc1)\n",
    "print(\"ENV_NAME:\", ENV_NAME)\n",
    "print(\"suffix:\", suffix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_file_to_df(file_name):\n",
    "\n",
    "    with open(file_name, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Initialize empty lists to store comments and functions\n",
    "    comments = []\n",
    "    functions = []\n",
    "\n",
    "\n",
    "    current_comment = \"\"\n",
    "    current_function = \"\"\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"#'\"):\n",
    "            current_comment += line[2:] + \" \"\n",
    "            if current_function:\n",
    "                current_function = current_function + ' \\n\\n###\\n\\n'\n",
    "                functions.append(current_function)\n",
    "                current_function = \"\"\n",
    "        else:\n",
    "            current_function += line + \" \"\n",
    "            if current_comment:\n",
    "                current_comment = current_comment\n",
    "                comments.append(current_comment.strip())\n",
    "                current_comment = \"\"\n",
    "\n",
    "\n",
    "    # If there are remaining comments or functions after the last function\n",
    "    if current_comment:\n",
    "        comments.append(current_comment.strip())\n",
    "    if current_function:\n",
    "        functions.append(current_function.strip())\n",
    "    df = pd.DataFrame({\"Comments\": comments, \"Functions\": functions})\n",
    "    df.rename(columns={'Comments':'prompt', 'Functions':'completion'}, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = from_file_to_df(source_functions_loc1)\n",
    "df.to_csv('prepared_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "EnvironmentLocationNotFound: Not a conda environment: /opt/homebrew/anaconda3/envs/{ENV_NAME}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Based on your file extension, your file is formatted as a CSV file\n",
      "- Your file contains 32 prompt-completion pairs. In general, we recommend having at least a few hundred examples. We've found that performance tends to linearly increase for every doubling of the number of examples\n",
      "- There are 1 examples that are very long. These are rows: [20]\n",
      "For conditional generation, and for classification the examples shouldn't be longer than 2048 tokens.\n",
      "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
      "- Your data does not contain a common ending at the end of your completions. Having a common ending string appended to the end of the completion makes it clearer to the fine-tuned model where the completion should end. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples.\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Necessary] Your format `CSV` will be converted to `JSONL`\n",
      "- [Recommended] Remove 1 long examples [Y/n]: Y\n",
      "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: Y\n",
      "- [Recommended] Add a suffix ending ` END` to all completions [Y/n]: Y\n",
      "- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: Y\n",
      "\n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
      "\n",
      "Wrote modified file to `prepared_data_prepared (1).jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"prepared_data_prepared (1).jsonl\"\n",
      "\n",
      "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\" END\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 3.89 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='conda run -n {ENV_NAME}; openai tools fine_tunes.prepare_data --file prepared_data.csv --quiet', returncode=0)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run('conda run -n {ENV_NAME}; openai tools fine_tunes.prepare_data --file prepared_data.csv --quiet', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upload progress: 100%|██████████| 32.4k/32.4k [00:00<00:00, 17.7Mit/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file from prepared_data_prepared (1).jsonl: file-08oeCz54DXZYgA68elsLCjle\n",
      "Created fine-tune: ft-A9xnjwvsONP7MRDB3wqZXdA2\n",
      "Streaming events until fine-tuning is complete...\n",
      "\n",
      "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
      "[2023-06-17 16:38:45] Created fine-tune: ft-A9xnjwvsONP7MRDB3wqZXdA2\n",
      "\n",
      "Stream interrupted (client disconnected).\n",
      "To resume the stream, run:\n",
      "\n",
      "  openai api fine_tunes.follow -i ft-A9xnjwvsONP7MRDB3wqZXdA2\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=\"conda run -n nlp; openai -k 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 api fine_tunes.create -t 'prepared_data_prepared (1).jsonl' --model ada --suffix 'survival '\", returncode=0)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run( f\"conda run -n {ENV_NAME}; openai -k {API_KEY} api fine_tunes.create -t 'prepared_data_prepared (1).jsonl' --model {model_engine} --suffix {suffix}\", shell=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
